{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b0029e-5a99-4066-83ce-92628370f8cc",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "* Before the model receives the data, we need to pre-process and tokenize it. The following notebook will explore the best way to do that. https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277d2dea-934b-4a04-b97f-396faa68de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e66785-2745-4060-9169-a54b3a896536",
   "metadata": {},
   "source": [
    "### Dataset Selection\n",
    "* Found more related dataset - prepared by Stanford for their Alpaca model, it is a series of prompts and responses from OpenAI's text-davinci-003\n",
    "* 52k unique instructions\n",
    "* https://github.com/tatsu-lab/stanford_alpaca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6692b3cf-23fd-42ca-aeca-5dc1edecf96f",
   "metadata": {},
   "source": [
    "### Modify Data for our Needs\n",
    "* Original data was split into instruction, input, and answer\n",
    "* We are only interested in two columns (input and answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a4902-d2b5-4a21-b651-3739bad98770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_json(\"datasets/alpaca/alpaca_data.json\")\n",
    "# df[\"instruction\"] = df[\"instruction\"].fillna(\"\") + \" \" + df[\"input\"].fillna(\"\")\n",
    "# df = df.drop(columns=[\"input\"])\n",
    "\n",
    "# split = int(len(df) * 0.80)\n",
    "# train_df = df.iloc[:split]\n",
    "# test_df = df.iloc[split:]\n",
    "# train_df.to_csv(\"datasets/alpaca/train.csv\")\n",
    "# test_df.to_csv(\"datasets/alpaca/test.csv\")\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b76791-8044-4718-ab2a-2996b7aa44ce",
   "metadata": {},
   "source": [
    "### Prep Dataframe as Iterator for vocab\n",
    "* We combine train and test to ensure all words in each are included in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90595808-cfa2-4e18-9bfc-e8bae5216f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "      <td>1.Eat a balanced diet and make sure to include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the three primary colors?</td>\n",
       "      <td>The three primary colors are red, blue, and ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe the structure of an atom.</td>\n",
       "      <td>An atom is made up of a nucleus, which contain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can we reduce air pollution?</td>\n",
       "      <td>There are a number of ways to reduce air pollu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Describe a time when you had to make a difficu...</td>\n",
       "      <td>I had to make a difficult decision when I was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0              Give three tips for staying healthy.    \n",
       "1                What are the three primary colors?    \n",
       "2                Describe the structure of an atom.    \n",
       "3                  How can we reduce air pollution?    \n",
       "4  Describe a time when you had to make a difficu...   \n",
       "\n",
       "                                              output  \n",
       "0  1.Eat a balanced diet and make sure to include...  \n",
       "1  The three primary colors are red, blue, and ye...  \n",
       "2  An atom is made up of a nucleus, which contain...  \n",
       "3  There are a number of ways to reduce air pollu...  \n",
       "4  I had to make a difficult decision when I was ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"datasets/alpaca/train.csv\")\n",
    "test_df = pd.read_csv(\"datasets/alpaca/test.csv\")\n",
    "frames = [train_df, test_df]\n",
    "comb_df = pd.concat(frames)\n",
    "comb_df = comb_df.drop(comb_df.columns[0], axis=1)\n",
    "comb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52a5d6e-06bd-4d19-82a3-fa6fb66d521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths match? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lengths match? {len(train_df) + len(test_df) == len(comb_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10d09e-1c75-4c36-a8d2-b1c3ad936250",
   "metadata": {},
   "source": [
    "* Next, we combine question and answer into a single column (just need to put all words in vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5c5487-d2c5-4a91-aa43-13334a736667",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df[\"instruction\"] = comb_df[\"instruction\"].fillna(\"\") + \" \" + comb_df[\"output\"].fillna(\"\")\n",
    "comb_df = comb_df.drop(columns=[\"output\"]).rename(columns={\"instruction\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fae903-f7f7-4472-88db-703175340ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Give three tips for staying healthy.  1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2963a940-67bb-4f7d-9a76-c556079f09b9",
   "metadata": {},
   "source": [
    "* Turn df into iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3224eefb-a7d6-48b4-b0f2-3b4533e14f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rows(df):\n",
    "    for row in df.itertuples(index=False):\n",
    "        yield str(row)\n",
    "\n",
    "combined_text = gen_rows(comb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bf113-3fcb-4790-89b0-f0f00d8b4a73",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "* Torch has a built-in tokenizer, but it apparently is very naive. By combinind with another library (spacy), we can have a more nuanced understanding (not just a simple split, understands that \"don't\" should be split into \"do\" and \"not\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c7ad44-4827-40f4-b9ed-cab364077439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98078345-2118-4773-bbc2-5908b67d8a05",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "* This vocabularly associates integer values with each token extracted by our tokenizer. This process can take a while (we make an entry for EVERY token in our dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9478569-e832-4c2c-991e-5d440318da07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(combined_text), min_freq=1, specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "torch.save(vocab, 'vocabs/alpaca/vocab.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18a8ef-9e04-4ad0-a4db-5e4802536ea3",
   "metadata": {},
   "source": [
    "* Because this previous process is so slow, we save the object after the initial calculation. This allows us to simply load the object in later iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93f2c645-6569-4976-9726-3bff1bd6fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load('vocabs/alpaca/vocab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ba77088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.vocab.vocab.Vocab"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0120e52-3e18-4d02-8657-53cc19d16d2d",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "* This dataset also cleans up the data, removing entries with questions or answers that are too long\n",
    "* Fills each entry with padding up to maximum length value (to keep things consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44419704-2d11-45c5-a8e7-4816b7c47133",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"datasets/alpaca\")\n",
    "from alpaca_dataset import Alpaca_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d8be8c-c90c-4187-b05e-4003f081d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Alpaca_Dataset(\"datasets/alpaca/train.csv\", vocab, tokenizer)\n",
    "test_dataset = Alpaca_Dataset(\"datasets/alpaca/test.csv\", vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec23236a-8daa-4a54-a2f5-608d98c10f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset,\"datasets/alpaca/train_dataset.pth\")\n",
    "torch.save(test_dataset,\"datasets/alpaca/test_dataset.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c021bfd-0cf1-492c-983d-009eb4c1f9e1",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e71ffd04-cbef-4bf1-90b2-8385a0171731",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(train_dataset,batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae0d0ba5-3bb6-42ca-8593-292f37e4fb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  876,     5,    38,  ...,     1,     1,     1],\n",
       "         [18889,     8,   240,  ...,     1,     1,     1],\n",
       "         [ 6041,     8,  3874,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [  754,     8,  5810,  ...,     1,     1,     1],\n",
       "         [ 3176,     5,   229,  ...,     1,     1,     1],\n",
       "         [ 8023,    24,   933,  ...,     1,     1,     1]]),\n",
       " tensor([[   2,   17,  674,  ...,    1,    1,    1],\n",
       "         [   2,   17,  240,  ...,    1,    1,    1],\n",
       "         [   2,   17, 3874,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   2,   50,  548,  ...,    1,    1,    1],\n",
       "         [   2, 1201,   39,  ...,    1,    1,    1],\n",
       "         [   2,   50, 3253,  ...,    1,    1,    1]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464d57b-51d9-4c9d-9ff0-8cb9ab4c943b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
